TIRA_IMAGE_TO_EXECUTE=registry.webis.de/code-research/tira/tira-user-tira-ir-starter/pyterrier:0.0.1-tira-docker-software-id-regional-flagstone
TIRA_VM_ID=tira-ir-starter
TIRA_COMMAND_TO_EXECUTE=/workspace/pyterrier_cli.py --input $inputDataset --output $outputDir --params wmodel=InL2 --rerank True --retrieval_pipeline default_pipelines.wmodel_text_scorer
TIRA_SOFTWARE_ID=docker-software-722
TIRA_DATASET_ID=clueweb12-trec-web-2014-20230107-training
TIRA_RUN_ID=2023-02-12-11-32-35
TIRA_CPU_COUNT=1
TIRA_MEMORY_IN_GIBIBYTE=10
TIRA_GPU=0
TIRA_DATA=no
TIRA_DATASET_TYPE=training
TIRA_TASK_ID=ir-benchmarks
TIRA_EVALUATOR_TRANSACTION_ID=ab6f8e29-5620-44f0-baa3-7e0f98800c92
TIRA_GIT_ID=eval---clueweb12-trec-web-2014-20230107-training---tira-ir-starter---2023-02-12-11-32-35---started-2023-02-12-11-32-35
TIRA_EVALUATION_IMAGE_TO_EXECUTE=webis/ir_measures_evaluator:1.0.5
TIRA_EVALUATION_COMMAND_TO_EXECUTE=/ir_measures_evaluator.py --run ${inputRun}/run.txt --topics ${inputDataset}/queries.jsonl --qrels ${inputDataset}/qrels.txt --output_path ${outputDir} --measures "P@10" "nDCG@10" "MRR"
TIRA_EVALUATION_SOFTWARE_ID=clueweb12-trec-web-2014-20230107-training-evaluator
TIRA_INPUT_RUN_DATASET_ID=clueweb12-trec-web-2014-20230107-training
TIRA_INPUT_RUN_VM_ID=tira-ir-starter
TIRA_INPUT_RUN_RUN_ID=2023-02-06-11-08-21
TIRA_INPUT_RUN_REPLACES_ORIGINAL_DATASET=true