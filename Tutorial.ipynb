{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada62d9a-445b-412e-97e0-332901d59370",
   "metadata": {},
   "source": [
    "# Post-Hoc Experimentation for [Retrieval Benchmarks in the IR Experiment Platform](https://www.tira.io/task/ir-benchmarks)\n",
    "\n",
    "This notebook showcases how post-hoc experiments of the IR Experiment Platform can be conducted.\n",
    "\n",
    "To start the notebook, please clone the archived shared task repository:\n",
    "\n",
    "```\n",
    "git@github.com:tira-io/ir-experiment-platform-benchmarks.git\n",
    "```\n",
    "\n",
    "Inside the cloned repository, you can start the Jupyter notebook which automatically installs a minimal virtual environment using:\n",
    "```\n",
    "make jupyterlab\n",
    "```\n",
    "\n",
    "The notebook covers:\n",
    "\n",
    "- 1.) Diving into artifacts submitted to some shared task\n",
    "- 2.) Re-evaluation of submitted approaches (e.g., a different subset of the data or different measures)\n",
    "- 3.) Execution of submitted approaches on new or manipulated data (e.g., for ablation studies or ensembles)\n",
    "\n",
    "All software submissions and evaluators come as docker images.\n",
    "Hence, you a minimal environment is sufficient: You need `Python3` and `Docker`.\n",
    "\n",
    "The installation of the environment is simplified with a virtual environment and executing `make jupyterlab` installs the virtual environment (if not already done) and starts the jupyter notebook ready to run all parts of the tutorial.\n",
    "\n",
    "For each of the softwares submitted to TIRA, the `tira` integration to PyTerrier loads the Docker Image submitted to TIRA to execute it in PyTerrier pipelines (i.e., a first execution could take sligthly longer).\n",
    "\n",
    "Other notebooks show other use-cases as tutorials:\n",
    "\n",
    "- [full-rank-retriever-tutorial.ipynb](full-rank-retriever-tutorial.ipynb): showcases how full-rankers can be reproduced/replicated.\n",
    "- [re-rank-tutorial.ipynb](re-rank-tutorial.ipynb): showcases how re-rankers can be reproduced/replicated.\n",
    "- [interoparability-tutorial](interoparability-tutorial): showcases how full-rankers and re-rankers submitted in TIRA can be combined in new ways in post-hoc experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e11ece-1b08-4149-963c-f80380c8be46",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53aba3b7-6d2b-4a27-88f1-d7c40b6978a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "from tira.local_client import Client\n",
    "tira = Client()\n",
    "\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a8c64-a42e-4f8a-9316-d092e0e3552f",
   "metadata": {},
   "source": [
    "# 1.) Overview of Artifacts submitted to the Shared Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52bb8ce-71ca-4210-9f10-568e479debd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>image</th>\n",
       "      <th>command</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>clueweb09-en-trec-web-2011-20230107-training</td>\n",
       "      <td>webis/ir_measures_evaluator:1.0.5</td>\n",
       "      <td>/ir_measures_evaluator.py --run ${inputRun}/run.txt --topics ${inputDataset}/queries.jsonl --qrels ${inputDataset}/qrels.txt --output_path ${outputDir} --measures \"P@10\" \"nDCG@10\" \"MRR\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dataset  \\\n",
       "count   33                                             \n",
       "unique  33                                             \n",
       "top     clueweb09-en-trec-web-2011-20230107-training   \n",
       "freq    1                                              \n",
       "\n",
       "                                    image  \\\n",
       "count   33                                  \n",
       "unique  1                                   \n",
       "top     webis/ir_measures_evaluator:1.0.5   \n",
       "freq    33                                  \n",
       "\n",
       "                                                                                                                                                                                          command  \n",
       "count   33                                                                                                                                                                                         \n",
       "unique  1                                                                                                                                                                                          \n",
       "top     /ir_measures_evaluator.py --run ${inputRun}/run.txt --topics ${inputDataset}/queries.jsonl --qrels ${inputDataset}/qrels.txt --output_path ${outputDir} --measures \"P@10\" \"nDCG@10\" \"MRR\"  \n",
       "freq    33                                                                                                                                                                                         "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of evaluators\n",
    "tira.all_evaluators().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6aabd7e-f2f4-4b62-874c-b2eb69cb4a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>team</th>\n",
       "      <th>image</th>\n",
       "      <th>command</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ir-benchmarks/tira-ir-starter/DuoT5 Top-25 (tira-ir-starter-pyterrier)</td>\n",
       "      <td>tira-ir-starter</td>\n",
       "      <td>docker.io/webis/ir-benchmarks-submissions:tira-ir-starter-duot5-0-0-1-duot5-base-msmarco-tira-docker-software-id-felt-slide</td>\n",
       "      <td>/reranking.py --input $inputDataset --output $outputDir --score_function cos_sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      approach  \\\n",
       "count   75                                                                       \n",
       "unique  75                                                                       \n",
       "top     ir-benchmarks/tira-ir-starter/DuoT5 Top-25 (tira-ir-starter-pyterrier)   \n",
       "freq    1                                                                        \n",
       "\n",
       "                   team  \\\n",
       "count   75                \n",
       "unique  1                 \n",
       "top     tira-ir-starter   \n",
       "freq    75                \n",
       "\n",
       "                                                                                                                              image  \\\n",
       "count   75                                                                                                                            \n",
       "unique  75                                                                                                                            \n",
       "top     docker.io/webis/ir-benchmarks-submissions:tira-ir-starter-duot5-0-0-1-duot5-base-msmarco-tira-docker-software-id-felt-slide   \n",
       "freq    1                                                                                                                             \n",
       "\n",
       "                                                                                 command  \n",
       "count   75                                                                                \n",
       "unique  51                                                                                \n",
       "top     /reranking.py --input $inputDataset --output $outputDir --score_function cos_sim  \n",
       "freq    9                                                                                 "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Overview of softwares\n",
    "tira.all_softwares().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd629b2-f73b-4a16-957e-531bfbb7ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>antique-test-20230107-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dataset\n",
       "count   33                            \n",
       "unique  33                            \n",
       "top     antique-test-20230107-training\n",
       "freq    1                             "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tira.all_datasets().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef897e66-bac3-4407-b10d-1b9f2b19a2b5",
   "metadata": {},
   "source": [
    "# 2.) Re-execute re-ranking approaches submitted to a shared task\n",
    "\n",
    "We run the approach `'ir-benchmarks/tira-ir-starter/SBERT multi-qa-MiniLM-L6-dot-v1 (tira-ir-starter-beir)'` on a small dataset.\n",
    "Therefore, we create a re-ranking dataset, and build a pipeline:\n",
    "\n",
    "```\n",
    "bm25\n",
    "\n",
    "advanced_pipeline = bm25 >> tira.pt.reranker('ir-benchmarks/tira-ir-starter/SBERT multi-qa-MiniLM-L6-dot-v1 (tira-ir-starter-beir)')\n",
    "```\n",
    "\n",
    "There, `ir-benchmarks` is the task that contains many retrieval datasets, `tira-ir-starter` is the team (i.e., the baseline team), and `SBERT multi-qa-MiniLM-L6-dot-v1 (tira-ir-starter-beir)` is the appraoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8694d81-bc03-42a7-b8e7-dafd68aceb11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>body</th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>this is the first document of many documents</td>\n",
       "      <td>1</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>this is another document</td>\n",
       "      <td>1</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>the topic of this document is unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docno                                          body qid           query\n",
       "0  d1    this is the first document of many documents  1   first document\n",
       "1  d2    this is another document                      1   first document\n",
       "2  d3    the topic of this document is unknown         1   first document"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_rerank = pd.DataFrame([\n",
    "        [\"d1\", \"this is the first document of many documents\", \"1\", \"first document\"],\n",
    "        [\"d2\", \"this is another document\", \"1\", \"first document\"],\n",
    "        [\"d3\", \"the topic of this document is unknown\", \"1\", \"first document\"]\n",
    "    ], columns=[\"docno\", \"body\", \"qid\", \"query\"])\n",
    "\n",
    "data_to_rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd8b1df-1bdd-4b5f-affc-c9089b2dadf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>body</th>\n",
       "      <th>qid</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>this is the first document of many documents</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.560003e-01</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>this is another document</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.085859e-10</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>the topic of this document is unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.681316e-02</td>\n",
       "      <td>first document</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docno                                          body qid  rank         score  \\\n",
       "0  d1    this is the first document of many documents  1   0     5.560003e-01   \n",
       "1  d2    this is another document                      1   2    -3.085859e-10   \n",
       "2  d3    the topic of this document is unknown         1   1     5.681316e-02   \n",
       "\n",
       "            query  \n",
       "0  first document  \n",
       "1  first document  \n",
       "2  first document  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = pt.text.scorer(wmmodel='bm25')\n",
    "\n",
    "bm25(data_to_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faed158c-f3e0-4984-9e19-0bce9fa1bdad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>body</th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>q0</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>system</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>this is the first document of many documents</td>\n",
       "      <td>1</td>\n",
       "      <td>first document</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.084885</td>\n",
       "      <td>multi-qa-MiniLM-L6-dot-v1-dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>this is another document</td>\n",
       "      <td>1</td>\n",
       "      <td>first document</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.802025</td>\n",
       "      <td>multi-qa-MiniLM-L6-dot-v1-dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>the topic of this document is unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>first document</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>37.294750</td>\n",
       "      <td>multi-qa-MiniLM-L6-dot-v1-dot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docno                                          body qid           query  q0  \\\n",
       "0  d1    this is the first document of many documents  1   first document  0    \n",
       "1  d2    this is another document                      1   first document  0    \n",
       "2  d3    the topic of this document is unknown         1   first document  0    \n",
       "\n",
       "   rank      score                         system  \n",
       "0  1     46.084885  multi-qa-MiniLM-L6-dot-v1-dot  \n",
       "1  2     40.802025  multi-qa-MiniLM-L6-dot-v1-dot  \n",
       "2  3     37.294750  multi-qa-MiniLM-L6-dot-v1-dot  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_pipeline = bm25 >> tira.pt.reranker('ir-benchmarks/tira-ir-starter/SBERT multi-qa-MiniLM-L6-dot-v1 (tira-ir-starter-beir)')\n",
    "\n",
    "advanced_pipeline(data_to_rerank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
